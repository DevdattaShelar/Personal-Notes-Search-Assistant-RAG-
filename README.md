## ğŸ—‚ Folder Structure

project/
â”‚â”€â”€ app.py
â”‚â”€â”€ rag_pipeline.py
â”‚â”€â”€ build_vector_db.py
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ data/ # Place your PDFs/TXT files here
â”‚â”€â”€ faiss_db/ # Auto-generated vector DB

# ğŸ“š Offline Personal Notes Search Assistant (RAG + Ollama + Streamlit)

An offline **Retrieval-Augmented Generation (RAG)** application that allows you to
search your **own PDF / TXT notes** using fully **local** AI models.

No API keys.  
No internet needed.  
Everything runs *offline* using **Ollama**, **FAISS**, and **Streamlit**.

---

## ğŸš€ Features

### âœ” 100% Offline  
Uses **local LLMs** and **local embeddings** â€” nothing is sent online.

### âœ” Works with Your Documents  
Supports:
- PDF files  
- TXT files  

Just place them inside the `data/` folder.

### âœ” Local Vector Database (FAISS)  
Your notes are embedded using:
- `all-minilm:33m` (local embedding model)

### âœ” Local LLM for answering  
By default uses:
- `qwen2:1.5b` (via Ollama)

### âœ” Clean & Simple UI  
Built with Streamlit.

---

## ğŸ›  Prerequisites

### 1ï¸âƒ£ Install Python 3.10+  
https://www.python.org/downloads/

### 2ï¸âƒ£ Install Ollama  
Download here:  
https://ollama.com/download

---

## ğŸ¤– Install Required Models in Ollama

Run these commands:

```sh
ollama pull all-minilm:33m
ollama pull qwen2:1.5b
